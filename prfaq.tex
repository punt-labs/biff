\documentclass[11pt,letterpaper]{article}

% ── Geometry ──────────────────────────────────────────────────────────────────
\usepackage[margin=1in]{geometry}

% ── Pagination ────────────────────────────────────────────────────────────────
\widowpenalty=10000          % No widow lines (last line alone at page top)
\clubpenalty=10000           % No orphan lines (first line alone at page bottom)
\brokenpenalty=10000         % No hyphenated words across page breaks
\raggedbottom                % Allow uneven page bottoms rather than stretching

% ── Fonts ─────────────────────────────────────────────────────────────────────
\usepackage[T1]{fontenc}
\usepackage{newpxtext}     % Palatino-based serif (TeX Gyre Pagella)
\usepackage{newpxmath}     % Matching math font

% ── Colors ────────────────────────────────────────────────────────────────────
\usepackage[dvipsnames]{xcolor}
\definecolor{SectionBlue}{HTML}{1B3A5C}
\definecolor{AccentGray}{HTML}{4A4A4A}
\definecolor{QuoteBorder}{HTML}{8B9DAF}
\definecolor{RiskRed}{HTML}{C0392B}
\definecolor{RiskAmber}{HTML}{E67E22}
\definecolor{RiskGreen}{HTML}{27AE60}
\definecolor{BoxBg}{HTML}{F7F8FA}

% ── Tables ────────────────────────────────────────────────────────────────────
\usepackage{booktabs}
\usepackage{tabularx}

% ── Boxes ─────────────────────────────────────────────────────────────────────
\usepackage[framemethod=tikz]{mdframed}

% ── Lists ─────────────────────────────────────────────────────────────────────
\usepackage{enumitem}

% ── Hyperlinks ────────────────────────────────────────────────────────────────
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=SectionBlue,
  urlcolor=SectionBlue,
  pdfauthor={Jim Freeman},
  pdftitle={biff — PR/FAQ},
  pdfsubject={Working Backwards — CLI Communication for Engineers},
}

% ── Section styling ───────────────────────────────────────────────────────────
\usepackage{titlesec}
\titleformat{\section}
  {\Large\bfseries\color{SectionBlue}}
  {}
  {0pt}
  {}
  [\vspace{-0.5em}\textcolor{QuoteBorder}{\rule{\textwidth}{0.4pt}}]

\titleformat{\subsection}
  {\large\bfseries\color{AccentGray}}
  {}
  {0pt}
  {}

% ══════════════════════════════════════════════════════════════════════════════
% Custom environments
% ══════════════════════════════════════════════════════════════════════════════

% ── \prsection{title} — styled press release section header ──────────────────
\newcommand{\prsection}[1]{%
  \vspace{1em}%
  {\large\bfseries\color{SectionBlue}#1}%
  \vspace{0.3em}\par%
}

% ── customerquote — indented, italic customer quote ──────────────────────────
\newmdenv[
  topline=false,
  bottomline=false,
  rightline=false,
  linewidth=3pt,
  linecolor=QuoteBorder,
  backgroundcolor=BoxBg,
  innerleftmargin=12pt,
  innerrightmargin=12pt,
  innertopmargin=8pt,
  innerbottommargin=8pt,
  skipabove=\baselineskip,
  skipbelow=\baselineskip,
]{customerquote}

% ── spokespersonquote — indented spokesperson quote ──────────────────────────
\newmdenv[
  topline=false,
  bottomline=false,
  rightline=false,
  linewidth=3pt,
  linecolor=SectionBlue,
  backgroundcolor=BoxBg,
  innerleftmargin=12pt,
  innerrightmargin=12pt,
  innertopmargin=8pt,
  innerbottommargin=8pt,
  skipabove=\baselineskip,
  skipbelow=\baselineskip,
]{spokespersonquote}

% ── faqpair — Q&A pair with bold question ────────────────────────────────────
\newenvironment{faqpair}[1]{%
  \vspace{0.5em}%
  \noindent\textbf{\color{SectionBlue}Q: #1}\par%
  \vspace{0.2em}%
  \begin{adjustwidth}{1em}{0pt}%
}{%
  \end{adjustwidth}%
  \vspace{0.5em}%
}

% ── riskitem — description-style risk entry (avoids table margin issues) ─────
\newcommand{\riskitem}[2]{%
  \vspace{0.4em}%
  \noindent\textbf{\color{SectionBlue}#1}\par%
  \vspace{0.1em}%
  \begin{adjustwidth}{1em}{0pt}%
    #2%
  \end{adjustwidth}%
}

% ── adjustwidth (for faqpair indentation) ────────────────────────────────────
\usepackage{changepage}

% ── Stage and version tracking ────────────────────────────────────────────────
\newcommand{\prfaqstage}{hypothesis}
\newcommand{\prfaqversion}[2]{v#1.#2}
\newcommand{\prfaqcurrentversion}{\prfaqversion{2}{2}}

% ══════════════════════════════════════════════════════════════════════════════
% Document
% ══════════════════════════════════════════════════════════════════════════════

\begin{document}

% ── Title block ───────────────────────────────────────────────────────────────
\begin{center}
  {\LARGE\bfseries\color{SectionBlue} biff} \\[0.5em]
  {\large\color{AccentGray} Team communication for engineers who never leave the terminal} \\[1.5em]
  {\small\color{AccentGray} February 2026 \quad|\quad Jim Freeman \quad|\quad punt-labs \quad|\quad \prfaqcurrentversion}
\end{center}

\vspace{1em}
\noindent\textcolor{QuoteBorder}{\rule{\textwidth}{0.8pt}}
\vspace{1em}

% ══════════════════════════════════════════════════════════════════════════════
% PRESS RELEASE
% ══════════════════════════════════════════════════════════════════════════════

\section*{Press Release}

\prsection{Summary}

San Francisco, CA --- August 2026 --- Today, punt-labs announced
\textbf{biff 1.0}, an open-source communication tool that lets software
engineers message teammates, check presence, coordinate agents, and broadcast
to their team --- all without leaving the terminal. Unlike Slack and Discord,
which demand a separate window and constant attention, biff runs inside the
engineer's existing Claude Code session as MCP-native slash commands.
Engineers type \texttt{/write @kai} the same way they type \texttt{git push}
--- in flow, with intent, and then move on.

\prsection{Problem}

Software engineers using AI-assisted coding tools like Claude Code are
experiencing a step change in productivity. Entire features that once took
days now take hours. But every time these engineers need to coordinate with a
teammate --- asking a question, sharing a diff, requesting a code review ---
they context-switch to Slack or Discord, tools designed for managers and
all-day-online knowledge workers, not for makers in deep focus.

The cost is not hypothetical. Gloria Mark's research at UC Irvine found that
a single interruption costs an average of 23 minutes and 15 seconds before a
worker returns to the original task.\footnote{Mark, G., Gudith, D., \&
Klocke, U. (2008). The Cost of Interrupted Work: More Speed and Stress.
\textit{Proc.\ CHI 2008}, ACM.} For an engineer shipping three features a
day with AI assistance, three Slack interruptions can erase an entire
feature's worth of productive time. Slack's always-on
presence model compounds the problem: even \emph{checking} for messages
breaks flow, and the social expectation of quick replies creates anxiety that
degrades concentration even when no message arrives.

As Thomas Dohmke, former CEO of GitHub, observed when launching
Entire: ``The terminal has become the new center of gravity on our
computers again'' --- and the best engineers can now run a dozen agents at
once.\footnote{Dohmke, T., ``Hello Entire World,'' Entire blog, February
2026, \url{https://entire.io/blog/hello-entire-world/}} The engineers
building the future of software --- the ones spending their entire day
inside a terminal, collaborating with AI agents, iterating at speeds that
would have seemed absurd two years ago --- have no communication tool that
matches how they actually work.

\prsection{Solution}

Biff brings communication into the terminal as slash commands borrowed from
the BSD Unix utilities that shipped with every workstation in the 1980s ---
\texttt{write}, \texttt{wall}, \texttt{finger}, \texttt{who},
and \texttt{mesg} --- updated for the MCP era. A typical morning might look
like this:

\begin{quote}
\ttfamily
\small
/plan ``refactoring the auth layer'' \\
/write @kai ``auth module is ready for review'' \\
/wall ``pulling the auth changes into the feature branch'' \\
\textnormal{\textit{...thirty minutes of focused work later...}} \\
/read
\end{quote}

Every command implies intent. There are no channels to monitor, no threads to
catch up on, no emoji reactions to parse. Communication is pull-based: when
someone sends you a message, your session notifies you --- your AI assistant
mentions it naturally (``You have 2 unread messages from @kai. Want me to read
them?'') and your terminal's status bar shows a live unread count. You decide
when to engage. The full command reference is in Appendix~A.

Because biff speaks MCP, it does not distinguish between a human session and
an agent session. An autonomous coding agent can \texttt{/plan} what it is
working on, broadcast status via \texttt{/wall}, \texttt{/write} a human when
it needs a decision, and show up in \texttt{/who} alongside everyone else.
When you have multiple agents working in the same codebase --- on the same
machine, in the same directory --- they coordinate to avoid stepping on each
other's files. Each agent gets a distinct identity via TTY sessions, and
\texttt{/who} shows host and directory per session so you can see when agents
share a filesystem. Workflow hooks tie into your development process: claiming
a task auto-sets your plan, creating a PR triggers a \texttt{/wall}
announcement. All messages are end-to-end encrypted via NaCl/libsodium, so
the relay never sees message contents. Biff is not just communication for
engineers --- it is the communication layer for the entire team of humans and
agents building software together.

\prsection{Customer Quote}

\begin{customerquote}
\textit{``I used to mass-quit my Slack channels once a month out of
frustration and then guiltily rejoin them. With biff, I just set
\texttt{/mesg n} when I'm deep in a problem and \texttt{/mesg y} when I
come up for air. My teammates can \texttt{/finger @priya} to see what I'm on
without interrupting. Now I run three agents alongside my own session ---
\texttt{/who} shows all four of us, each with its own plan, and when one of
them needs a decision it just \texttt{/write}s me. Last week I shipped more
in three days than I used to ship in two weeks, and I didn't miss a single
important message.''}

\raggedleft --- \textbf{Priya Chandrasekaran}, Senior Engineer at a Series B
startup
\end{customerquote}

\prsection{Getting Started}

Getting started with biff takes three commands:
\texttt{pip install biff-mcp}, then \texttt{biff install} to register the MCP
server and slash commands, then \texttt{biff doctor} to verify the setup.
Restart Claude Code, and you are live. Biff ships with a shared relay
on Synadia Cloud with end-to-end encryption, so there is zero infrastructure
to provision. Team configuration lives in a \texttt{.biff} file committed to
your git repository --- it only needs a team member list; the relay URL
defaults to the shared relay. Your display name is resolved automatically
from your GitHub identity. When you clone a repo that has a \texttt{.biff}
file, biff automatically connects you to the right team. There is no account
to create, no workspace to configure, and no browser to open. Type
\texttt{/who} to see your teammates. Within five minutes of installation, you
can send your first message, see your team's presence, and set your plan.

\prsection{Spokesperson Quote}

\begin{spokespersonquote}
``We built biff because we watched the best engineers in the world
disappear into their terminals --- shipping at speeds that make the old
sprint-and-standup cadence look quaint --- and then lose hours every day to
communication tools designed for a different era. Slack was built for the
open-office, always-online workplace. Biff is built for the deep-focus,
AI-accelerated one. We didn't add a chat feature to the terminal. We
resurrected the Unix communication vocabulary --- \texttt{write},
\texttt{wall}, \texttt{finger}, \texttt{who}, \texttt{mesg} --- because
those commands understood something Slack forgot: communication should be
purposeful, not ambient.''

\raggedleft --- \textbf{Jim Freeman}, Founder, punt-labs
\end{spokespersonquote}

\prsection{Call to Action}

Biff is open source and available today at
\href{https://github.com/punt-labs/biff}{github.com/punt-labs/biff}.
Install with \texttt{pip install biff-mcp}, then run \texttt{biff install}
and \texttt{biff doctor}. The core tool, end-to-end encryption, and the
shared relay are free and always will be. For larger teams that need uptime
guarantees, audit logs, and admin controls, biff teams is available as a
paid tier.

\newpage

% ══════════════════════════════════════════════════════════════════════════════
% FREQUENTLY ASKED QUESTIONS
% ══════════════════════════════════════════════════════════════════════════════

\section*{Frequently Asked Questions}

% ── External FAQs (Customer-facing) ──────────────────────────────────────────

\subsection*{External FAQs}

\begin{faqpair}{What is biff and who is it for?}
  Biff is a terminal-native communication tool for software engineers who
  use Claude Code or other MCP-compatible systems. If you spend your working
  day in a terminal and resent switching to a browser to talk to your team,
  biff is for you. It provides six slash commands covering messaging,
  presence, and availability control --- all without leaving your
  session. See Appendix~A for the full command reference.
\end{faqpair}

\begin{faqpair}{How is biff different from Slack?}
  Slack is a workplace chat platform designed around channels, threads, and
  continuous presence. It assumes you are watching. Biff is a communication
  tool designed around intent and focus. It assumes you are working. In
  Slack, the default state is ``available and monitoring.'' In biff, the
  default state is ``heads down; interrupt me if it matters.'' Slack is
  optimized for managers who need visibility. Biff is optimized for
  engineers who need concentration.

  Structurally, biff runs inside your existing development environment as
  MCP slash commands. There is no separate app, no browser tab, no
  notification center. Communication happens where your code already lives.
\end{faqpair}

\begin{faqpair}{How is biff different from Discord?}
  Discord is a community platform built around persistent voice and text
  channels. It works well for open-source communities and gaming. Biff is a
  team tool built around directed messages and explicit intent. Discord is
  for hanging out. Biff is for getting things done. Biff also runs natively
  inside your AI coding session --- there is no alt-tab.
\end{faqpair}

\begin{faqpair}{How do I get started?}
  Run \texttt{pip install biff-mcp}, then \texttt{biff install} to register
  the MCP server and slash commands, then \texttt{biff doctor} to verify the
  setup. Restart Claude Code. Biff ships with a shared demo relay on Synadia
  Cloud, so there is no infrastructure to provision. If your repo has a
  \texttt{.biff} file (committed by a teammate), biff picks up the team
  roster automatically. Your display name is resolved from your GitHub
  identity. Type \texttt{/who} to see your team. No account creation, no
  workspace to configure. You are communicating within five minutes.
\end{faqpair}

\begin{faqpair}{What happens to my messages? Is communication private?}
  Today, messages traverse the NATS relay in cleartext. The relay follows a
  POP mail model: messages are held only until the recipient reads them,
  then discarded. Biff is not a system of record. The shared demo relay is
  hosted on Synadia Cloud; teams that want data sovereignty can self-host
  the same NATS server and route all traffic through their own
  infrastructure. End-to-end encryption (NaCl/libsodium) ships with
  biff 1.0 and will make the relay unable to read message contents. Biff
  never analyzes or trains on your messages.
\end{faqpair}

\begin{faqpair}{Does biff work without Claude Code?}
  Biff is built on the Model Context Protocol (MCP), which is an open
  standard. Any MCP-compatible client can use biff. Claude Code is the
  primary target today because it has the largest population of engineers
  living in the terminal. As other MCP clients mature, biff will work there
  too.
\end{faqpair}

\begin{faqpair}{Will biff support real-time pairing or live conversation?}
  Real-time features are on the roadmap but not yet shipped.
  \texttt{/talk} would open a live text conversation between two terminals.
  \texttt{/pair} would allow a teammate to send input to your Claude Code
  session, with explicit per-session consent, full visibility for the
  session owner, and a kill switch at any time. Both features require
  careful security design and are scoped to a future phase.
\end{faqpair}

\begin{faqpair}{Can agents use biff?}
  Yes. Because biff is an MCP server, any MCP-compatible agent can use it
  the same way a human does. An autonomous coding agent can \texttt{/plan}
  what it is working on, \texttt{/write} a human when it needs a decision,
  and show up in
  \texttt{/who} alongside everyone else. Agents can also coordinate with
  other agents --- preventing duplicate work via \texttt{/plan} visibility,
  targeting messages with \texttt{/write}, and checking presence with
  \texttt{/who}. Biff does not distinguish between human and agent
  sessions. If it speaks MCP, it can participate. The next roadmap phase
  adds TTY sessions (each agent gets a distinct identity, targetable
  via \texttt{/write @user:tty}), enriched presence showing host and
  directory per session, and workflow hooks that automatically set plans
  and announce milestones.
\end{faqpair}

% ── Internal FAQs (Business-facing) ──────────────────────────────────────────

\subsection*{Internal FAQs}

\subsubsection*{Value \& Market}

\begin{faqpair}{What is the total addressable market?}
  The immediate market is engineers using AI coding assistants inside
  terminals. GitHub's Octoverse 2025 report counts over 180 million
  developers on the platform, with 36 million joining in the past year
  alone.\footnote{GitHub, ``Octoverse 2025,''
  \url{https://github.blog/news-insights/octoverse/octoverse-2025/}}
  AI-assisted coding adoption is accelerating --- GitHub Copilot reached
  20 million cumulative signups (1.3 million paid subscribers) by
  mid-2025, and Claude Code launched to strong adoption in early 2025. The subset of engineers who
  work primarily in the terminal with MCP-compatible tools is small today
  (estimated tens of thousands) but growing fast as MCP becomes the
  standard protocol for AI tool integration.

  Bottoms-up: if 50,000 engineers adopt biff in year one, and 20\% of them
  are on teams that convert to the paid hosted relay at \$10/user/month,
  that represents \$1.2M ARR. The real opportunity scales in two
  dimensions: as MCP adoption grows, the human addressable market
  multiplies; and as autonomous agents become standard members of
  engineering teams, the number of sessions that need coordination grows
  faster than headcount.
\end{faqpair}

\begin{faqpair}{What evidence do we have that customers want this?}
  Four categories of evidence:

  \begin{enumerate}[leftmargin=1.5em]
    \item \textbf{Behavioral signal:} The explosive growth of CLI-native
    tooling (Claude Code, Cursor's terminal mode, Warp, Ghostty) demonstrates
    that engineers are consolidating their workflow into the terminal. The
    ecosystem of MCP servers, Claude Code plugins, and slash commands exists
    precisely because engineers want to \emph{stay in flow}. Communication
    is the last major activity that forces them out.

    \item \textbf{Cultural signal:} Steve Yegge's February 2026 article
    ``The Anthropic Hive
    Mind''\footnote{Yegge, S., ``The Anthropic Hive Mind,'' Medium,
    February 2026,
    \url{https://steve-yegge.medium.com/the-anthropic-hive-mind-d01f768f3d7b}}
    profiles engineering teams where ``the whole team is pair programming
    at once'' and everyone sees each other's work in real time. He reports
    engineers achieving 10--100x productivity gains but argues this
    requires full transparency at AI speeds --- otherwise ``nobody will
    ever see what you are doing.'' This is exactly the problem biff
    solves: visibility and coordination at AI speed, inside the tool.

    \item \textbf{Investment signal:} Thomas Dohmke, former CEO of GitHub,
    launched Entire in February 2026 with a \$60M seed round --- the largest
    seed investment ever for a developer tools
    startup.\footnote{Dohmke, T., ``Hello Entire World,'' Entire blog,
    February 2026, \url{https://entire.io/blog/hello-entire-world/}}
    His thesis: ``the terminal has become the new center of gravity on our
    computers again.'' Entire focuses on the code context layer (how AI
    changes get reviewed and governed). Biff focuses on the human
    coordination layer (how engineers communicate while working at AI
    speed). The same tectonic shift creates both opportunities.

    \item \textbf{Historical precedent:} The original BSD Unix included
    \texttt{write}, \texttt{talk}, \texttt{wall}, \texttt{finger}, and
    \texttt{mesg} as standard utilities because the designers understood
    that engineers who share a system need lightweight, intentional
    communication. Those tools died when engineers left the terminal for
    GUIs. Now that engineers are returning to the terminal, the need has
    returned with them.
  \end{enumerate}
\end{faqpair}

\begin{faqpair}{How will engineers discover biff?}
  Three channels, in order of expected impact:

  \begin{enumerate}[leftmargin=1.5em]
    \item \textbf{Viral loop via \texttt{.biff} file.} When a team member
    commits a \texttt{.biff} file to a shared repo, every engineer who
    clones that repo encounters it. The install path is two commands. This
    is the primary growth mechanism: one adopter seeds an entire team.

    \item \textbf{Developer community launch.} Hacker News, dev
    Twitter/Bluesky, and the Claude Code plugin marketplace. The Unix
    nostalgia angle (``biff is back'') and the anti-Slack positioning
    generate organic interest. Target: 500 installs in the first week.

    \item \textbf{Content and conference talks.} Blog posts on
    terminal-native communication, talks at developer conferences. The
    open-source model means the project itself is the marketing --- every
    GitHub star, every fork, every \texttt{.biff} file committed is a
    distribution event.
  \end{enumerate}

  The cost of acquisition is near zero: the product is free, the
  distribution is organic, and the viral loop is built into the protocol.
  The risk is not cost-per-acquisition but time-to-critical-mass on each
  team.
\end{faqpair}

\begin{faqpair}{Who are the competitors and why will we win?}
  \textbf{Slack} is the dominant team communication tool but is
  increasingly resented by engineers for its interruption-driven model.
  Slack could build a CLI client, but its revenue depends on engagement
  metrics (messages sent, channels monitored, time-in-app) that are
  fundamentally opposed to biff's focus-first model. Slack's incentives
  make it structurally unable to optimize for fewer interruptions.

  \textbf{Discord} serves developer communities well but is not a team
  coordination tool. Its voice-channel model does not map to directed,
  intentional engineering communication.

  \textbf{GitHub} has discussions, issues, and PR comments --- all
  web-based, all requiring a browser. The \texttt{gh} CLI covers some
  workflows but offers no real-time messaging or presence.

  \textbf{Zulip} and \textbf{Mattermost} are open-source Slack
  alternatives with the same fundamental model: channels, threads, browser
  or desktop app. They solve the vendor-lock-in problem but not the
  context-switch problem.

  \textbf{Claude Code} (and other MCP hosts) could build messaging
  natively. This is the most credible competitive threat. Mitigation:
  biff is open source and protocol-level, not tied to a single host.
  Anthropic's incentive is to grow the MCP ecosystem, not to build every
  tool themselves. If Claude Code ships native messaging, biff's MCP
  protocol can interoperate with it rather than compete.

  Biff wins by refusing to play Slack's game. It is not a chat app with a
  CLI client. It is a communication protocol native to the environment
  where engineers already work. The moat is the MCP ecosystem: as more
  tools adopt MCP, biff's integration surface grows without additional
  development.
\end{faqpair}

\subsubsection*{Technical}

\begin{faqpair}{What are the major technical risks?}
  \begin{enumerate}[leftmargin=1.5em]
    \item \textbf{MCP notification mechanism (low risk, shipped).} The
    full chain --- message arrival, tool re-registration,
    \texttt{notifications/tools/list\_changed} over SSE, model
    awareness --- is shipped and working in production. When a message
    arrives, the model sees the updated tool description (e.g., ``Check
    messages (1 unread: @kai about auth)'') and proactively mentions it
    to the user. All MCP interactions are wrapped behind an internal
    abstraction layer for spec-maturity resilience.

    \item \textbf{User-visible notification gap (low risk, partially
    solved).} Dynamic tool descriptions are visible to the AI model but
    not directly to the human user in the Claude Code UI. Biff now ships
    optional status bar integration (\texttt{biff install-statusline})
    that shows a live unread count in the terminal. Combined with
    model-level awareness via tool descriptions, the notification gap
    is addressed through two complementary channels.

    \item \textbf{Message relay infrastructure (low risk, shipped).}
    The NATS relay is shipped and tested against hosted NATS on Synadia
    Cloud. Biff ships with a shared demo relay so teams can start with
    zero infrastructure. The relay follows a POP mail model: messages are
    stored only until the recipient reads them, then discarded. Teams
    that want data sovereignty can self-host the same single-binary NATS
    server.

    \item \textbf{Security of pairing (medium risk, future).} The
    \texttt{/pair} feature, which would allow one engineer to send input
    to another's Claude Code session, requires careful permission design.
    This is scoped to a future phase, giving time for the security model
    to mature.

    \item \textbf{Adoption chicken-and-egg (high risk).} Biff is only
    useful if your teammates also use it. Mitigation: the \texttt{.biff}
    file committed to the repo means the second person on a team only
    needs \texttt{pip install biff-mcp} and \texttt{biff install} ---
    the configuration is already there. The demo relay eliminates
    infrastructure setup. The \texttt{/plan}, \texttt{/finger}, and
    \texttt{/who} commands provide value to individual users even without
    teammates.
  \end{enumerate}
\end{faqpair}

\begin{faqpair}{What dependencies exist on other teams or systems?}
  Biff depends on the MCP protocol (maintained by Anthropic), Claude Code
  as the primary host client (also Anthropic), Python packaging
  infrastructure (PyPI), and NATS for the message relay. There are no
  dependencies on other punt-labs products. The relay server is a single
  NATS binary and can be self-hosted.
\end{faqpair}

\begin{faqpair}{Where does data live?}
  All data lives on the NATS relay. The relay serves three durability
  tiers:

  \textbf{Persistent}: \texttt{/plan} status is stored on the relay.
  Like the original BSD \texttt{\textasciitilde/.plan} file, it survives
  sessions, disconnects, and restarts. \texttt{/finger} reads the
  persistent plan and combines it with live presence.

  \textbf{Store-and-forward}: \texttt{/write} follows a POP mail model
  --- messages are held on the relay until the recipient runs
  \texttt{/read}, then discarded.

  \texttt{/who} and \texttt{/mesg y/n} are live presence state.
  \texttt{/wall} (team broadcast) is on the roadmap.

  The \texttt{.biff} file in the repository contains the team member
  list and optional relay configuration. It is the root of trust: adding
  your username to \texttt{.biff} and committing it proves you have
  commit access to the repo, which is what makes you a team member.
  End-to-end encryption ships with biff 1.0 and will make the relay
  unable to read message contents.
\end{faqpair}

\begin{faqpair}{What is the estimated development timeline?}
  \begin{description}[leftmargin=1.5em, labelwidth=10em, font=\bfseries]
    \item[Shipped] Core MCP server with \texttt{/write}, \texttt{/read},
    \texttt{/who}, \texttt{/plan}, \texttt{/finger},
    \texttt{/mesg y/n}. NATS-based relay for cross-machine messaging on
    Synadia Cloud. POP-model store-and-forward for \texttt{/write}.
    Status bar integration.
    Display names from GitHub identity. Released and in use.
    \item[Next: Agentic] \texttt{/wall} (team broadcast). TTY sessions
    (each agent gets a distinct identity, targetable via
    \texttt{/write @user:tty}). Enriched presence (\texttt{/who} shows
    host and directory per session). Plan auto-expand (\texttt{/plan
    biff-bf8} shows the task title). Workflow hooks (claiming a task
    auto-sets plan, creating a PR triggers \texttt{/wall}). Project
    opt-in (\texttt{/biff y} enables coordination per project).
    \item[Future: Security] End-to-end encryption (NaCl/libsodium),
    GitHub identity and auth, per-repo NATS credentials.
    \item[Future: Real-Time] \texttt{/talk} for live conversation,
    \texttt{/pair} for session sharing with explicit consent.
    \item[Future: Hosted] Managed relay service (biff teams). Admin
    controls, audit logs, retention policies. Billing integration.
  \end{description}
\end{faqpair}

\begin{faqpair}{What is the agentic coordination vision?}
  The most distinctive part of biff's roadmap is treating agents as
  first-class team members. Today, biff already makes no distinction
  between a human session and an agent session --- an autonomous coding
  agent can \texttt{/plan} what it is working on, \texttt{/write} a human
  when it needs a decision, and show up in \texttt{/who} alongside
  everyone else.

  The next phase makes this explicit. TTY sessions give each agent a
  distinct identity: one user running three agents shows three entries in
  \texttt{/who}, each targetable via \texttt{/write @user:tty}. Enriched
  presence shows host and directory per session, flagging when agents share
  a filesystem and need to coordinate to avoid file conflicts. Plan
  auto-expand (\texttt{/plan biff-bf8}) surfaces what each agent is working
  on without anyone looking it up. Workflow hooks automate the coordination
  overhead: claiming a task auto-sets your plan, creating a PR triggers a
  \texttt{/wall} announcement.

  The thesis is that as engineering teams grow to include both humans and
  autonomous agents, the coordination primitives --- presence, messaging,
  broadcast, targeted delivery --- matter more, not less. A team of three
  humans running nine agents across six machines needs the same visibility
  and communication that a team of twelve humans needs, but at higher speed
  and with less tolerance for manual ceremony.
\end{faqpair}

\begin{faqpair}{What is the scaling story?}
  The relay is a NATS JetStream instance --- a single Go binary that
  handles 100,000+ messages per second on one node. Horizontal scaling
  is straightforward: NATS supports clustering with Raft-based
  replication. The bottleneck at scale is presence: broadcasting
  \texttt{/who} status across thousands of users requires a gossip
  protocol. This is a solved problem and is not needed until biff reaches
  thousands of concurrent users. For the POP-model message relay, NATS
  JetStream consumers with acknowledge-and-delete provide exactly the
  retrieve-and-discard semantics biff requires.
\end{faqpair}

\subsubsection*{Business}

\begin{faqpair}{What is the revenue model?}
  Open core. The biff CLI tool, self-hosted relay, and shared demo relay
  are free and open source (MIT license). Revenue comes from
  \textbf{biff teams}, a hosted relay service priced at
  \$10/user/month for teams above the free tier:

  \begin{itemize}[leftmargin=1.5em]
    \item Free tier: up to 5 team members on the shared demo relay
    \item Paid tier: unlimited team members with 99.9\% uptime SLA
    \item Audit logs and compliance exports
    \item Team admin controls (permissions, onboarding, offboarding)
    \item Priority support
  \end{itemize}

  The paid tier is about team size and operational guarantees. This model
  is proven by GitLab, Sentry, PostHog, and other developer-tools
  companies. Engineers adopt the free tool; their companies pay for the
  managed version when the team grows and needs reliability guarantees.
\end{faqpair}

\begin{faqpair}{What are the key metrics for success?}
  \begin{description}[leftmargin=1.5em, labelwidth=10em, font=\bfseries]
    \item[Weekly active users] Target: 1,000 WAU within 6 months of
    launch. Measures adoption.
    \item[Messages per user/week] Target: 15+ messages/week for active
    users. Measures engagement without rewarding noise --- biff's
    intentional model should show \emph{fewer} messages per user than
    Slack but higher signal-to-noise.
    \item[Team conversion rate] Target: 10\% of teams with 3+ active free
    users convert to biff teams within 90 days.
    \item[Retention (D30)] Target: 40\% of installers still active after
    30 days. CLI tools typically see high install-and-forget rates; 40\%
    retention indicates genuine workflow integration.
  \end{description}

  Decision threshold: if WAU has not reached 500 within 4 months of
  public launch, revisit the go-to-market strategy. If D30 retention is
  below 20\%, the product is not sticky enough and needs fundamental
  rethinking.
\end{faqpair}

\begin{faqpair}{What is the next step to validate the vision?}
  Ship to 10 external beta teams within 60 days. Each team must have at
  least 3 members using biff as their primary coordination tool for a
  real project. Measure D30 retention and messages-per-user-per-week.
  Conduct post-trial interviews to understand what worked, what was
  missing, and whether users would pay for the hosted tier.

  If D30 retention is below 20\% across beta teams, the product is not
  solving a real problem and needs fundamental rethinking. If retention is
  above 40\% but conversion interest is zero, the free tier may be too
  generous or the paid tier insufficiently differentiated.
\end{faqpair}

\begin{faqpair}{What does the P\&L look like at steady state?}
  Assumptions (labeled): 10,000 paid users at \$10/user/month = \$1.2M
  ARR. Infrastructure costs are approximately \$2,000/month (NATS relay
  hosting on Synadia Cloud, monitoring, CI/CD). Support costs are minimal
  at this scale given the CLI-native user base and open-source community.
  Gross margin exceeds 95\%.

  Break-even requires approximately 200 paid users (\$2,000/month
  revenue vs.\ \$2,000/month infrastructure). The path to break-even is
  short because infrastructure costs are near-constant up to tens of
  thousands of users --- NATS is designed for high-throughput messaging
  with minimal per-message overhead. The primary cost at scale is
  engineering headcount, not infrastructure.
\end{faqpair}

\begin{faqpair}{Why now? What has changed?}
  Three things changed simultaneously, and the convergence is visible in
  real dollars and real behavior:

  \begin{enumerate}[leftmargin=1.5em]
    \item \textbf{Engineers returned to the terminal.} After two decades of
    IDE dominance, AI coding tools brought engineers back to the command
    line. Claude Code, Cursor's terminal mode, and the MCP ecosystem mean
    the terminal is once again the primary workspace for a growing
    population of engineers. Dohmke calls this ``the new center of
    gravity'' and bet \$60M on it. Yegge profiles engineering teams
    achieving 10--100x productivity gains by working entirely inside
    terminal sessions with AI agents.

    \item \textbf{MCP created a standard protocol.} Before MCP, building a
    communication tool inside a coding environment meant integrating with
    every editor separately. MCP provides a single integration point that
    works across any compatible client. Biff integrates once and works
    everywhere MCP does.

    \item \textbf{AI-accelerated engineers outgrew Slack.} When engineers
    ship 3--5x faster, the communication overhead that was tolerable at the
    old pace becomes the bottleneck. Slack's interruption model was
    designed for a world where shipping a feature took a sprint. In a world
    where shipping a feature takes a morning, Slack's model actively
    harms productivity.
  \end{enumerate}
\end{faqpair}

\begin{faqpair}{What are we not building?}
  Biff is not building:
  \begin{itemize}[leftmargin=1.5em]
    \item \textbf{Persistent channels or temporary groups.} No channels,
    no rooms, no \texttt{/hive}. Communication is directed: you message a
    person or broadcast to the team. There is no concept of a persistent
    or temporary room.
    \item \textbf{Artifact sharing (\texttt{/send}).} Sending diffs, files,
    or code snippets inline is a compelling idea but out of scope for now.
    Use git, GitHub Issues, or PR comments for artifact exchange.
    \item \textbf{Inline code review (\texttt{/cr}).} Requesting and
    conducting code review inside the terminal is future work. GitHub's
    review workflow remains the system of record.
    \item \textbf{Message history or search.} Messages are ephemeral by
    default. Biff is not a system of record.
    \item \textbf{Video or voice.} Biff is text. If you need a video call,
    use the tool built for video calls.
    \item \textbf{Project management.} No tasks, no boards, no sprints.
    Biff is communication, not coordination. Use beads, Linear, or GitHub
    Issues for project tracking.
    \item \textbf{A mobile app.} Biff is for engineers at their terminals.
    If you are on your phone, you are not in the target workflow.
  \end{itemize}
\end{faqpair}

% ══════════════════════════════════════════════════════════════════════════════
% FOUR RISKS ASSESSMENT
% ══════════════════════════════════════════════════════════════════════════════

\section*{Risk Assessment}

\begin{mdframed}[
  linewidth=0.5pt,
  linecolor=QuoteBorder,
  backgroundcolor=BoxBg,
  innerleftmargin=10pt,
  innerrightmargin=10pt,
  innertopmargin=10pt,
  innerbottommargin=10pt,
]
{\bfseries\color{SectionBlue}Four Risks Assessment}\par
\vspace{0.5em}

\riskitem{Value}{%
  \textbf{Medium risk.} Strong circumstantial evidence (CLI adoption trend,
  MCP ecosystem growth, Yegge's observations about AI-speed collaboration)
  and early artisanal validation --- the builders use biff daily for their
  own coordination. The risk is not ``do engineers dislike Slack?'' (they do)
  but ``is the pain severe enough to adopt a new tool?'' Slack's network
  effects are powerful --- even engineers who hate Slack use it because their
  team does. Biff must provide enough standalone value (\texttt{/plan},
  \texttt{/finger}) to bootstrap adoption before network effects kick in.
  The artisanal signal is positive: the tool is in daily use by its
  creators. The remaining risk is whether that signal generalizes beyond the
  builders.}

\riskitem{Usability}{%
  \textbf{Low risk.} The slash-command interface mirrors patterns engineers
  already use (git commands, Unix utilities, Claude Code slash commands).
  Installation is three commands (\texttt{pip install}, \texttt{biff
  install}, \texttt{biff doctor}). Time-to-value is under five minutes. The
  primary usability risk is discoverability: new users need to learn the
  command vocabulary. Mitigation: the vocabulary is small (6 shipped
  commands), the names are intuitive (borrowed from Unix), and the tool
  descriptions are self-documenting within Claude Code. The secondary
  usability risk is the empty-room experience: a solo installer sees no
  teammates and may not persist long enough for network effects to form.
  Mitigation: the \texttt{.biff} file viral loop means most users arrive
  on a team that already has at least one other member.}

\riskitem{Feasibility}{%
  \textbf{Low risk (shipped).} The core architecture is not just validated
  --- it is shipped and in production. The MCP notification mechanism,
  NATS JetStream relay (tested against hosted NATS on Synadia Cloud),
  dynamic tool descriptions, model-visible message awareness, and status
  bar integration are all working. The notification gap --- the
  highest-uncertainty component at design time --- is addressed through two
  channels: model-level awareness via tool descriptions and user-level
  awareness via the status bar. The highest-risk future component is
  \texttt{/pair}, which requires careful permission design for session
  input sharing. End-to-end encryption (NaCl/libsodium) ships with
  biff 1.0. No shipped component required novel technology.}

\riskitem{Viability}{%
  \textbf{Medium risk.} The open-core model is proven in developer tools,
  but biff's intentional low-volume communication model means engagement
  metrics will look different from typical SaaS. Investors and boards
  accustomed to Slack-style engagement numbers may question whether ``15
  messages per user per week'' constitutes a healthy product. The counter:
  biff's value is measured in time saved, not messages sent. The free-to-paid
  conversion trigger is team size (free for up to 5, paid beyond that),
  which aligns with natural adoption: one engineer installs, teammates
  follow, and the team hits the threshold organically. The risk is
  reaching that critical mass of team adoption quickly enough to
  demonstrate the conversion funnel.}

\end{mdframed}

\newpage

% ══════════════════════════════════════════════════════════════════════════════
% APPENDIX A: COMMAND REFERENCE
% ══════════════════════════════════════════════════════════════════════════════

\section*{Appendix A: Command Reference}

Commands are organized by status: \textbf{Shipped} commands are released and
working today. \textbf{Next} features are the immediate roadmap focus.
\textbf{Future} features are planned but not yet scheduled. \textbf{Won't Do
(for now)} features are out of scope.

\subsection*{Shipped: Core Communication}

\renewcommand{\arraystretch}{1.4}
\begin{tabularx}{\textwidth}{@{}l l X@{}}
  \toprule
  \textbf{Command} & \textbf{Origin} & \textbf{Description} \\
  \midrule

  \texttt{/write @user ``text''} & BSD \texttt{write} &
  Send a one-way message to a user. Asynchronous --- the recipient reads
  it when they choose via \texttt{/read}. \\

  \texttt{/read} & BSD \texttt{from} &
  Check your inbox. Shows unread messages with sender, timestamp, and
  content. \\

  \texttt{/finger @user} & BSD \texttt{finger} &
  Read a user's plan and current status.
  Non-intrusive --- the target is not notified. \\

  \texttt{/who} & BSD \texttt{who} &
  List all active sessions. Shows who is online, their availability
  (\texttt{/mesg y/n}), and their current plan. \\

  \texttt{/plan ``text''} & BSD \texttt{.plan} &
  Set your status message. Visible to anyone who runs \texttt{/finger}
  or \texttt{/who}. Update it as your work changes. Provides single-user
  value without teammates. \\

  \texttt{/mesg y} | \texttt{n} & BSD \texttt{mesg} &
  Control whether you receive messages. When off (\texttt{n}), incoming
  messages are queued until you turn it back on (\texttt{y}). \\

  \bottomrule
\end{tabularx}

\subsection*{Next: Agentic Coordination}

\renewcommand{\arraystretch}{1.4}
\begin{tabularx}{\textwidth}{@{}l X@{}}
  \toprule
  \textbf{Feature} & \textbf{Description} \\
  \midrule

  \texttt{/wall ``text''} (team broadcast) &
  Broadcast a message to your full team. Ephemeral --- if you are not
  connected when it happens, you miss it, just like BSD \texttt{wall}. \\

  TTY sessions &
  Each agent gets a distinct identity. One user with 3 sessions shows 3
  entries in \texttt{/who}, targetable via \texttt{/write @user:tty}. \\

  Enriched presence &
  \texttt{/who} shows host and directory per session. Flags when agents
  share a filesystem. \\

  Plan auto-expand &
  \texttt{/plan biff-bf8} auto-expands to show the task title. Everyone
  sees what you are working on without looking it up. \\

  Workflow hooks &
  Claiming a task auto-sets your plan. Creating a PR triggers a
  \texttt{/wall} announcement. \\

  Project opt-in &
  \texttt{/biff y} enables the coordination workflow per project via
  \texttt{AGENTS.md}. \\

  \bottomrule
\end{tabularx}

\subsection*{Future: Network \& Security}

\renewcommand{\arraystretch}{1.4}
\begin{tabularx}{\textwidth}{@{}l X@{}}
  \toprule
  \textbf{Feature} & \textbf{Description} \\
  \midrule

  E2E encryption &
  NaCl/libsodium (Curve25519 + XSalsa20-Poly1305). Messages encrypted
  with recipient's public key; relay stores ciphertext it cannot read. \\

  GitHub identity \& auth &
  Authenticate users via GitHub identity. Per-repo NATS credentials for
  team isolation. \\

  \bottomrule
\end{tabularx}

\subsection*{Future: Real-Time \& Pairing}

\renewcommand{\arraystretch}{1.4}
\begin{tabularx}{\textwidth}{@{}l l X@{}}
  \toprule
  \textbf{Command} & \textbf{Origin} & \textbf{Description} \\
  \midrule

  \texttt{/talk @user} & BSD \texttt{talk} &
  Open a real-time bidirectional conversation via model-mediated message
  exchange. \\

  \texttt{/pair @user} & --- &
  Invite a user to send input to your Claude Code session. Requires
  explicit acceptance. The session owner sees all input and retains full
  control. \\

  \bottomrule
\end{tabularx}

\subsection*{Won't Do (for now)}

\renewcommand{\arraystretch}{1.4}
\begin{tabularx}{\textwidth}{@{}l X@{}}
  \toprule
  \textbf{Feature} & \textbf{Rationale} \\
  \midrule

  \texttt{/send @user} (artifact sharing) &
  Sending diffs, files, or code snippets inline. Compelling but out of
  scope --- use git or GitHub for artifact exchange. \\

  \texttt{/cr @user} (code review) &
  Inline code review in the terminal. GitHub's review workflow remains the
  system of record. \\

  \texttt{/hive @a @b @c} (temporary groups) &
  Temporary multi-person groups that dissolve when work is done. Directed
  messaging (\texttt{/write}) and broadcast (\texttt{/wall}, on roadmap)
  cover the coordination need
  without the complexity of group lifecycle management. \\

  \bottomrule
\end{tabularx}

\end{document}
